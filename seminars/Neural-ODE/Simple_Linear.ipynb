{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "keras = tf.keras\n",
    "initializers = tf.keras.initializers\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = np.random.RandomState(34121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2\n",
    "h_0 = np.ones([1, N])\n",
    "h_0 = tf.to_float(h_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(N, kernel_initializer=initializers.random_normal(stddev=0.01), use_bias=False)\n",
    "\n",
    "tf.stop_gradient(layer.weights)    \n",
    "\n",
    "def module(state):\n",
    "    output = layer(state)    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ODEFunc(state, t):\n",
    "    h_t = state\n",
    "    h_output = module(h_t)\n",
    "    return h_output\n",
    "\n",
    "\n",
    "def ODEFuncBackward(state, t):    \n",
    "    h_t = state\n",
    "    h_output = -module(h_t)\n",
    "    return h_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, info = tf.contrib.integrate.odeint(\n",
    "    func=ODEFunc,\n",
    "    y0=h_0,\n",
    "    t=[0.0, 100.0],\n",
    "    rtol=1e-6,\n",
    "    atol=1e-6,\n",
    "    full_output=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.variables_initializer(layer.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.run(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.0738602,  3.1465704]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_Wt = tf.linalg.expm(\n",
    "    layer.weights[0] * 100,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "tf.matmul(h_0, exp_Wt).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.run(layer(tf.to_float(h_0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'odeint:0' shape=(2, 1, 2) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice:0' shape=(1, 2) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_N = output[-1, ...]\n",
    "h_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.reduce_sum(h_N**2)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.2017975"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLdh0 = tf.gradients(loss, h_0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'gradients/AddN:0' shape=(1, 2) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfLdh0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.035124, 16.368471]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfLdh0.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_output, inv_info = tf.contrib.integrate.odeint(\n",
    "    func=ODEFuncBackward,\n",
    "    y0=h_N,\n",
    "    t=[0.0, 100.0],\n",
    "    rtol=1e-6,\n",
    "    atol=1e-12,\n",
    "    full_output=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000006, 1.       ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_output[-1, ...].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'gradients_2/pow_grad/Reshape:0' shape=(1, 2) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfLdhN = tf.gradients(loss, h_N)[0]\n",
    "dfLdhN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.1477146,  6.2931433]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfLdhN.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamics(ht, dL):\n",
    "    ht = tf.stop_gradient(ht)\n",
    "    dL = tf.stop_gradient(dL)\n",
    "    with tf.Graph().as_default() as g:\n",
    "        h_output = - module(ht)\n",
    "        jvp_h = - tf.gradients(h_output, ht, grad_ys=dL)[0]\n",
    "    \n",
    "    return h_output, jvp_h\n",
    "\n",
    "\n",
    "def ODEFuncBackwardWithGrad(state, t):    \n",
    "    hN, dfLdhN = tf.unstack(state)\n",
    "    h_output, jvp_h = dynamics(hN, dfLdhN)    \n",
    "    return tf.stack([h_output, jvp_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'EagerPyFunc_14:1' shape=<unknown> dtype=float32>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_output, jvp_h = tfe.py_func(dynamics, [h_N, dfLdhN], [tf.float32, tf.float32])\n",
    "\n",
    "jvp_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_output, inv_info = tf.contrib.integrate.odeint(\n",
    "    func=ODEFuncBackwardWithGrad,\n",
    "    y0=[h_N, dfLdhN],\n",
    "    t=[0.0, 100.0],\n",
    "    rtol=1e-6,\n",
    "    atol=1e-6,\n",
    "    full_output=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_rec, dfLdh0_rec = tf.unstack(inv_output[-1, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000011 , 0.99999994]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0_rec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.035125, 16.368467]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfLdh0_rec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_exp = tf.reduce_sum(tf.matmul(h_0, exp_Wt)**2)\n",
    "dfLdh0_exp = tf.gradients(loss_exp, h_0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.9073486e-06,  1.3351440e-05]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfLdh0_exp.eval() - dfLdh0_rec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'strided_slice:0' shape=(1, 2) dtype=float32>,\n",
       " <tf.Tensor 'gradients_2/pow_grad/Reshape:0' shape=(1, 2) dtype=float32>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_N, dfLdhN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_variables(ht, at, theta):\n",
    "    tensor = tf.concat([tf.reshape(ht, [-1]), tf.reshape(at, [-1]), tf.reshape(theta, [-1])], 0)    \n",
    "    return tensor\n",
    "\n",
    "\n",
    "def unpack_variables(state):\n",
    "    ht = tf.reshape(state[:2], [1, 2])\n",
    "    at = tf.reshape(state[2:4], [1, 2])\n",
    "    theta = tf.reshape(state[4:], [2, 2])    \n",
    "    return ht, at, theta\n",
    "\n",
    "\n",
    "share_variables = lambda func: tf.make_template(\n",
    "    func.__name__, func, create_scope_now_=True)\n",
    "\n",
    "\n",
    "@share_variables\n",
    "def module_backprop_template(ht, at): \n",
    "    ht = tf.stop_gradient(ht)    \n",
    "    W = tf.stop_gradient(layer.weights[0])        \n",
    "    # ht_output = - module(ht) # does not work :(\n",
    "    ht_output = - tf.matmul(ht, W)    \n",
    "    jvp_z = - tf.gradients(ht_output, ht, grad_ys=at)[0]    \n",
    "    jvp_theta = - tf.gradients(ht_output, W, grad_ys=at)[0]\n",
    "    return ht_output, jvp_z, jvp_theta\n",
    "\n",
    "\n",
    "def ODEFuncBackwardFullWithGrad(state, t):    \n",
    "\n",
    "    hN, dfLdhN, theta = unpack_variables(state)   \n",
    "    ht_output, jvp_z, jvp_theta = module_backprop_template(hN, dfLdhN)    \n",
    "    return pack_variables(ht_output, jvp_z, jvp_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_4:0' shape=(8,) dtype=float32>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack_variables(h_N, dfLdhN, tf.zeros_like(layer.weights[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_last = tf.to_float(h_N.eval())\n",
    "dfLdhN_last = tf.to_float(dfLdhN.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"asd\"):\n",
    "    inv_output= tf.contrib.integrate.odeint(\n",
    "        func=ODEFuncBackwardFullWithGrad,\n",
    "        y0=pack_variables(h_last, dfLdhN_last, tf.zeros_like(layer.weights[0])),\n",
    "        t=[0.0, 100.0],\n",
    "        rtol=1e-6,\n",
    "        atol=1e-6,\n",
    "        full_output=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ValueError: Cannot compute gradient inside while loop with respect to op 'odeint/dense/kernel'. We do not support taking the gradient wrt or through the initial value of a loop variable. Gradients can be computed through loop invariants or wrt the input parameters to the loop body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_rec, dfLdh0_rec, dLdTheta_rec = unpack_variables(inv_output[-1, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000001 , 0.9999995]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0_rec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.0351305, 16.368464 ]], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfLdh0_rec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 369.10162 ,  256.72568 ],\n",
       "       [  26.418175, 2471.258   ]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLdTheta_rec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.run(module_backprop_template(h_last, dfLdhN_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_exp = tf.reduce_sum(tf.matmul(h_0, exp_Wt)**2)\n",
    "dfLdTheta_exp = tf.gradients(loss_exp, layer.weights[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.0517578e-05, -1.8920898e-03],\n",
       "       [-1.3008118e-03,  4.8828125e-04]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfLdTheta_exp.eval() - dLdTheta_rec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 369.09937 ,  256.72662 ],\n",
       "       [  26.416153, 2471.255   ]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gradients(loss, layer.weights[0])[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision-tf1.12",
   "language": "python",
   "name": "vision-tf1.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
