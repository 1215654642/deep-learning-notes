{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import tensorflow as tf\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.eager as tfe\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(tf.keras.Model):\n",
    "    \n",
    "  def __init__(self):\n",
    "    super(Module, self).__init__(name='Module')        \n",
    "    self.dense_1 = keras.layers.Dense(3, activation='sigmoid')\n",
    "    self.dense_2 = keras.layers.Dense(3, activation='sigmoid')\n",
    "\n",
    "  def call(self, inputs):    \n",
    "    x = self.dense_1(inputs)    \n",
    "    return self.dense_2(x)\n",
    "\n",
    "  def compute_output_shape(self, input_shape):\n",
    "    shape = tf.TensorShape(input_shape).as_list()\n",
    "    shape[-1] = 3\n",
    "    return tf.TensorShape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EulerSolver(fun, state, dt):    \n",
    "    dstate = fun(state)\n",
    "    return [h + dt * dh for h, dh in zip(state, dstate)]\n",
    "\n",
    "\n",
    "def RK2Solver(fun, state, dt):    \n",
    "    k1 = fun(state)    \n",
    "    k2 = fun([s + dt * k for s,k in zip(state, k1)])\n",
    "    return [h + dt * (a + b)/2 for h, a, b in zip(state, k1, k2)]\n",
    "\n",
    "\n",
    "class NeuralODE:\n",
    "    def __init__(self, module_fn, solver, num_steps: int = 40):\n",
    "        self._num_steps = num_steps\n",
    "        self._dt = 1 / num_steps\n",
    "        self._module_fn = module_fn\n",
    "        self._solver = solver\n",
    "        \n",
    "    def forward(self, h_input):\n",
    "        \n",
    "        def _forward_dynamics(h):\n",
    "            return [self._module_fn(h[0])]\n",
    "        \n",
    "        state = [h_input]\n",
    "        for k in range(self._num_steps):            \n",
    "            state = self._solver(_forward_dynamics, state, self._dt)\n",
    "        return state[0]\n",
    "    \n",
    "    def _backward_dynamics(self, state):\n",
    "        ht = state[0]\n",
    "        at = - state[1]\n",
    "        \n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(ht)\n",
    "            ht_new = self._module_fn(ht)\n",
    "\n",
    "        gradients = g.gradient(\n",
    "            target= ht_new, \n",
    "            sources=[ht] + self._module_fn.weights, \n",
    "            output_gradients=at\n",
    "        )\n",
    "        return [ht_new, *gradients]\n",
    "        \n",
    "    def backward(self, h_output, grad_h_output):\n",
    "        \n",
    "        num_weights = len(self._module_fn.weights) + 1\n",
    "        dWeights = [tf.zeros_like(w) for w in self._module_fn.weights]\n",
    "        neg_dt = - self._dt\n",
    "        ht = h_output\n",
    "        at = grad_h_output\n",
    "        \n",
    "        state = [h_output, grad_h_output, *dWeights]\n",
    "        for k in range(self._num_steps):\n",
    "            \n",
    "            state = self._solver(self._backward_dynamics, state, neg_dt)\n",
    "            \n",
    "        return state[0], state[1], state[2:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = Module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_h = tf.to_float(np.random.randn(*[1, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=61087, shape=(1, 3), dtype=float32, numpy=array([[ 0.39672357, -0.17706469,  0.5449612 ]], dtype=float32)>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_ode = NeuralODE(mdl, EulerSolver, num_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_end = neural_ode.forward(input_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=90728, shape=(1, 3), dtype=float32, numpy=array([[1.644217  , 0.36412543, 2.3599567 ]], dtype=float32)>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as g:\n",
    "    g.watch(h_end)\n",
    "    loss = tf.reduce_sum(h_end**2)\n",
    "    \n",
    "dLoss_dh_end = g.gradient(loss, h_end)\n",
    "dLoss_dh_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as g:\n",
    "    g.watch(input_h)\n",
    "    h_end = neural_ode.forward(input_h)    \n",
    "\n",
    "auto_gradients = g.gradient(h_end, [input_h, *mdl.weights], dLoss_dh_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as g:\n",
    "    g.watch(input_h)\n",
    "    h_end = neural_ode.forward(input_h)\n",
    "    loss = tf.reduce_sum(h_end**2)\n",
    "\n",
    "auto_gradients_loss = g.gradient(loss, [input_h, *mdl.weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf.reduce_sum(ag - ag_loss).numpy() for ag, ag_loss in zip(auto_gradients, auto_gradients_loss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_start, dfdh0, dWeights = neural_ode.backward(h_end, dLoss_dh_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=91823, shape=(1, 3), dtype=float32, numpy=array([[0.00130136, 0.00374753, 0.00073708]], dtype=float32)>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.abs((h_start - input_h) / h_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=91826, shape=(1, 3), dtype=float32, numpy=array([[ 1.3487248e-05, -2.1883039e-05,  2.4345043e-06]], dtype=float32)>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dfdh0 - auto_gradients[0]) / auto_gradients[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.017087633, 0.00011493638, 0.0060084797, 0.00045181066]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf.reduce_sum(tf.abs(dw - auto_wd)).numpy() for dw, auto_wd in zip(dWeights, auto_gradients[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_ode_rk2 = NeuralODE(mdl, RK2Solver, num_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_end_rk2 = neural_ode_rk2.forward(input_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=93405, shape=(1, 3), dtype=float32, numpy=array([[1.6447359 , 0.36479747, 2.3595555 ]], dtype=float32)>"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as g:\n",
    "    g.watch(h_end_rk2)\n",
    "    loss = tf.reduce_sum(h_end_rk2**2)\n",
    "    \n",
    "dLoss_dh_end = g.gradient(loss, h_end_rk2)\n",
    "dLoss_dh_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as g:\n",
    "    g.watch(input_h)\n",
    "    h_end_rk2 = neural_ode_rk2.forward(input_h)    \n",
    "\n",
    "auto_gradients = g.gradient(h_end_rk2, [input_h, *mdl.weights], dLoss_dh_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_start, dfdh0, dWeights = neural_ode_rk2.backward(h_end_rk2, dLoss_dh_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=96376, shape=(1, 3), dtype=float32, numpy=array([[-2.2536344e-07, -0.0000000e+00,  0.0000000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h_start - input_h) / h_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=96350, shape=(1, 3), dtype=float32, numpy=array([[1.671073 , 0.3547482, 2.3500018]], dtype=float32)>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdh0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=96380, shape=(1, 3), dtype=float32, numpy=array([[ 1.4267397e-07, -3.3603905e-07, -2.0290923e-07]], dtype=float32)>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dfdh0 - auto_gradients[0]) / auto_gradients[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.296897e-09, 7.450581e-09, 1.3411045e-07, 8.940697e-08]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf.reduce_sum(tf.abs(dw - auto_wd)).numpy() for dw, auto_wd in zip(dWeights, auto_gradients[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_h = tf.to_float(np.random.randn(*[32, 3]))\n",
    "neural_ode = NeuralODE(mdl, RK2Solver, num_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_end = neural_ode_rk2.forward(input_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(32), Dimension(3)])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as g:\n",
    "    g.watch(h_end)\n",
    "    loss = tf.reduce_sum(h_end**2)\n",
    "    \n",
    "dLoss_dh_end = g.gradient(loss, h_end)\n",
    "dLoss_dh_end.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_start, dfdh0, dWeights = neural_ode.backward(h_end, dLoss_dh_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as g:\n",
    "    g.watch(input_h)\n",
    "    h_end = neural_ode.forward(input_h)    \n",
    "    loss = tf.reduce_sum(h_end**2)\n",
    "\n",
    "auto_gradients = g.gradient(loss, [input_h, *mdl.weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.1945685e-05, 4.656613e-07, 1.1920929e-07, 2.5331974e-06, 9.536743e-07]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf.reduce_sum(tf.abs(dw - auto_wd)).numpy() for dw, auto_wd in zip([dfdh0, *dWeights], auto_gradients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision-tf1.12",
   "language": "python",
   "name": "vision-tf1.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
