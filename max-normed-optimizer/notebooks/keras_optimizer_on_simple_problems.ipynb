{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_optimizer as keras_opt\n",
    "import keras_mnist_mlp as mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, validation_set, input_shape = mlp.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    model = mlp.get_mlp(num_layers=3, lantent_size=256, activation='relu', l2_reg=1e-4)\n",
    "    return model\n",
    "\n",
    "model = model_fn()\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.4574 - acc: 0.8991 - val_loss: 0.2329 - val_acc: 0.9617\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.1979 - acc: 0.9691 - val_loss: 0.1875 - val_acc: 0.9696\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.1560 - acc: 0.9789 - val_loss: 0.1709 - val_acc: 0.9732\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.1342 - acc: 0.9834 - val_loss: 0.1563 - val_acc: 0.9766\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.1185 - acc: 0.9859 - val_loss: 0.1471 - val_acc: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb51dc25c50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_fn()\n",
    "optimizer = keras_opt.NormalizedSGD(\n",
    "    lr=0.1, lr_update=0.02, lr_max=0.1, lr_min=1e-6, lr_force=0.0, norm='max')\n",
    "\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(\n",
    "    x=x_train, y=y_train, \n",
    "    batch_size=batch_size, \n",
    "    epochs=5, \n",
    "    validation_data=validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0029461044,\n",
       " 0.00021495039,\n",
       " 0.0022092862,\n",
       " 0.000117403535,\n",
       " 0.0016923719,\n",
       " 7.776696e-05,\n",
       " 0.00017348005,\n",
       " 2.862806e-05]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "[K.eval(lr) for lr in optimizer.learning_rates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 1.1656 - acc: 0.7152 - val_loss: 0.4539 - val_acc: 0.8997\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.4286 - acc: 0.9051 - val_loss: 0.3804 - val_acc: 0.9178\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.3823 - acc: 0.9170 - val_loss: 0.3552 - val_acc: 0.9249\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.3604 - acc: 0.9227 - val_loss: 0.3443 - val_acc: 0.9253\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.3472 - acc: 0.9263 - val_loss: 0.3325 - val_acc: 0.9310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb506cec8d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_fn()\n",
    "optimizer = keras_opt.NormalizedSGD(\n",
    "    lr=0.001, lr_update=0.02, lr_max=0.1, lr_min=1e-6, lr_force=0.0, norm='l2')\n",
    "\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(\n",
    "    x=x_train, y=y_train, \n",
    "    batch_size=batch_size, \n",
    "    epochs=5, \n",
    "    validation_data=validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0060673496,\n",
       " 0.0005181226,\n",
       " 0.0009084636,\n",
       " 0.00022583488,\n",
       " 0.0006139646,\n",
       " 0.00012608299,\n",
       " 0.0003583707,\n",
       " 2.4732488e-05]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "[K.eval(lr) for lr in optimizer.learning_rates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.2934 - acc: 0.9345 - val_loss: 0.1719 - val_acc: 0.9694\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.1678 - acc: 0.9705 - val_loss: 0.1719 - val_acc: 0.9686\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.1381 - acc: 0.9789 - val_loss: 0.1623 - val_acc: 0.9709\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.1219 - acc: 0.9822 - val_loss: 0.1398 - val_acc: 0.9763\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.1133 - acc: 0.9837 - val_loss: 0.1394 - val_acc: 0.9777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb51c80b320>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "model = model_fn()\n",
    "adam_optimizer = Adam(0.001)\n",
    "\n",
    "model.compile(adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(\n",
    "    x=x_train, y=y_train, \n",
    "    batch_size=batch_size, \n",
    "    epochs=5, \n",
    "    validation_data=validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "receptivefield",
   "language": "python",
   "name": "receptivefield"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
